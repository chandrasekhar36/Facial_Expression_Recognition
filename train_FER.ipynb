{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chandrasekhar36/Facial_Expression_Recognition/blob/master/train_FER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0NeJaNjEA76",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcBLi8jIEdL1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "830ee498-d3ef-4c70-9e2c-30f64b27b30b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hUl5wpGD_gu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from matplotlib import pyplot\n",
        "from math import sqrt \n",
        "import numpy as np \n",
        "import scipy.misc \n",
        "from IPython.display import display \n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator \n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization,GlobalAveragePooling2D\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.regularizers import l1, l2\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "from sklearn.utils import shuffle\n",
        "from keras.models import load_model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "batch_size=64\n",
        "img_height=48\n",
        "img_width=48"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TltYeF7bD_g2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator( \n",
        "    rescale=1./255,\n",
        "    rotation_range = 10,\n",
        "    horizontal_flip = True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    validation_split=0.2,\n",
        "    fill_mode = 'nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator( \n",
        "    rescale=1./255\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpcmxfglD_g8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d8268bfe-fc24-4c52-a103-62d596ff6aee"
      },
      "source": [
        "training_set = train_datagen.flow_from_directory(\n",
        "    \"/content/drive/My Drive/data_2\",\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training') \n",
        "\n",
        "test_set = train_datagen.flow_from_directory(\n",
        "    \"/content/drive/My Drive/data_2\",\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation') "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3317 images belonging to 4 classes.\n",
            "Found 827 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFLEahkwD_hC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d956eede-4167-4566-f791-c6021753ce41"
      },
      "source": [
        "model=VGG16(include_top=False,input_shape=(48,48,3))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKi1XGBND_hH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#flat=Flatten()(model.outputs)\n",
        "flat = GlobalAveragePooling2D()(model.output)\n",
        "x = Dense(1024,activation='relu')(flat)\n",
        "output= Dense(4, activation='softmax')(x)\n",
        "model = Model(inputs=model.inputs, outputs=output)\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE7T9fp4D_hN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1f99d6a5-b16f-4912-b1b3-4312417aca67"
      },
      "source": [
        "modelH=model.fit_generator(training_set,\n",
        "                         epochs = 200,\n",
        "                         shuffle=True,\n",
        "                         validation_data = test_set)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "52/52 [==============================] - 388s 7s/step - loss: 1.0078 - accuracy: 0.5761 - val_loss: 1.7879 - val_accuracy: 0.1632\n",
            "Epoch 2/200\n",
            "52/52 [==============================] - 396s 8s/step - loss: 0.9358 - accuracy: 0.5957 - val_loss: 1.7319 - val_accuracy: 0.1971\n",
            "Epoch 3/200\n",
            "52/52 [==============================] - 377s 7s/step - loss: 0.8984 - accuracy: 0.6180 - val_loss: 1.6672 - val_accuracy: 0.2104\n",
            "Epoch 4/200\n",
            "52/52 [==============================] - 375s 7s/step - loss: 0.8391 - accuracy: 0.6497 - val_loss: 1.6643 - val_accuracy: 0.2080\n",
            "Epoch 5/200\n",
            "52/52 [==============================] - 375s 7s/step - loss: 0.7790 - accuracy: 0.6816 - val_loss: 1.7292 - val_accuracy: 0.2406\n",
            "Epoch 6/200\n",
            "52/52 [==============================] - 381s 7s/step - loss: 0.7586 - accuracy: 0.6883 - val_loss: 2.1080 - val_accuracy: 0.2322\n",
            "Epoch 7/200\n",
            "52/52 [==============================] - 379s 7s/step - loss: 0.7272 - accuracy: 0.6994 - val_loss: 2.1627 - val_accuracy: 0.2213\n",
            "Epoch 8/200\n",
            "52/52 [==============================] - 374s 7s/step - loss: 0.7070 - accuracy: 0.7088 - val_loss: 2.2353 - val_accuracy: 0.2297\n",
            "Epoch 9/200\n",
            "52/52 [==============================] - 371s 7s/step - loss: 0.6422 - accuracy: 0.7419 - val_loss: 1.9866 - val_accuracy: 0.2237\n",
            "Epoch 10/200\n",
            "52/52 [==============================] - 373s 7s/step - loss: 0.6287 - accuracy: 0.7398 - val_loss: 2.1694 - val_accuracy: 0.2310\n",
            "Epoch 11/200\n",
            "52/52 [==============================] - 372s 7s/step - loss: 0.6342 - accuracy: 0.7407 - val_loss: 2.2671 - val_accuracy: 0.1935\n",
            "Epoch 12/200\n",
            "52/52 [==============================] - 370s 7s/step - loss: 0.6507 - accuracy: 0.7401 - val_loss: 2.0784 - val_accuracy: 0.2140\n",
            "Epoch 13/200\n",
            "52/52 [==============================] - 375s 7s/step - loss: 0.6054 - accuracy: 0.7552 - val_loss: 2.2594 - val_accuracy: 0.1838\n",
            "Epoch 14/200\n",
            "52/52 [==============================] - 375s 7s/step - loss: 0.5502 - accuracy: 0.7802 - val_loss: 2.0845 - val_accuracy: 0.2297\n",
            "Epoch 15/200\n",
            "52/52 [==============================] - 374s 7s/step - loss: 0.5429 - accuracy: 0.7841 - val_loss: 2.5754 - val_accuracy: 0.1947\n",
            "Epoch 16/200\n",
            "52/52 [==============================] - 376s 7s/step - loss: 0.5336 - accuracy: 0.7932 - val_loss: 2.7088 - val_accuracy: 0.2297\n",
            "Epoch 17/200\n",
            "52/52 [==============================] - 379s 7s/step - loss: 0.5039 - accuracy: 0.8010 - val_loss: 2.4859 - val_accuracy: 0.2310\n",
            "Epoch 18/200\n",
            "52/52 [==============================] - 374s 7s/step - loss: 0.4773 - accuracy: 0.8055 - val_loss: 2.6542 - val_accuracy: 0.2346\n",
            "Epoch 19/200\n",
            "52/52 [==============================] - 373s 7s/step - loss: 0.4891 - accuracy: 0.8046 - val_loss: 2.7918 - val_accuracy: 0.2164\n",
            "Epoch 20/200\n",
            "52/52 [==============================] - 381s 7s/step - loss: 0.4975 - accuracy: 0.7932 - val_loss: 2.4568 - val_accuracy: 0.2116\n",
            "Epoch 21/200\n",
            "52/52 [==============================] - 389s 7s/step - loss: 0.4470 - accuracy: 0.8128 - val_loss: 2.8387 - val_accuracy: 0.2334\n",
            "Epoch 22/200\n",
            "52/52 [==============================] - 394s 8s/step - loss: 0.4430 - accuracy: 0.8282 - val_loss: 3.7912 - val_accuracy: 0.2334\n",
            "Epoch 23/200\n",
            "52/52 [==============================] - 402s 8s/step - loss: 0.4684 - accuracy: 0.8158 - val_loss: 2.4610 - val_accuracy: 0.2261\n",
            "Epoch 24/200\n",
            "52/52 [==============================] - 395s 8s/step - loss: 0.4344 - accuracy: 0.8285 - val_loss: 2.5289 - val_accuracy: 0.2213\n",
            "Epoch 25/200\n",
            "52/52 [==============================] - 405s 8s/step - loss: 0.4162 - accuracy: 0.8294 - val_loss: 2.1938 - val_accuracy: 0.2273\n",
            "Epoch 26/200\n",
            "52/52 [==============================] - 402s 8s/step - loss: 0.4252 - accuracy: 0.8273 - val_loss: 3.1349 - val_accuracy: 0.2406\n",
            "Epoch 27/200\n",
            "52/52 [==============================] - 397s 8s/step - loss: 0.4274 - accuracy: 0.8312 - val_loss: 3.1029 - val_accuracy: 0.2080\n",
            "Epoch 28/200\n",
            "52/52 [==============================] - 375s 7s/step - loss: 0.4104 - accuracy: 0.8450 - val_loss: 2.7782 - val_accuracy: 0.2297\n",
            "Epoch 29/200\n",
            "52/52 [==============================] - 377s 7s/step - loss: 0.4055 - accuracy: 0.8294 - val_loss: 3.3403 - val_accuracy: 0.2249\n",
            "Epoch 30/200\n",
            "52/52 [==============================] - 377s 7s/step - loss: 0.3997 - accuracy: 0.8450 - val_loss: 3.1745 - val_accuracy: 0.2382\n",
            "Epoch 31/200\n",
            "52/52 [==============================] - 380s 7s/step - loss: 0.4109 - accuracy: 0.8390 - val_loss: 2.8981 - val_accuracy: 0.2237\n",
            "Epoch 32/200\n",
            "52/52 [==============================] - 391s 8s/step - loss: 0.4081 - accuracy: 0.8396 - val_loss: 3.0913 - val_accuracy: 0.2044\n",
            "Epoch 33/200\n",
            "52/52 [==============================] - 394s 8s/step - loss: 0.3684 - accuracy: 0.8583 - val_loss: 2.9153 - val_accuracy: 0.2164\n",
            "Epoch 34/200\n",
            "52/52 [==============================] - 383s 7s/step - loss: 0.3575 - accuracy: 0.8625 - val_loss: 3.2949 - val_accuracy: 0.2406\n",
            "Epoch 35/200\n",
            "52/52 [==============================] - 382s 7s/step - loss: 0.3587 - accuracy: 0.8562 - val_loss: 3.0892 - val_accuracy: 0.2177\n",
            "Epoch 36/200\n",
            "52/52 [==============================] - 386s 7s/step - loss: 0.3667 - accuracy: 0.8550 - val_loss: 3.6555 - val_accuracy: 0.1959\n",
            "Epoch 37/200\n",
            "52/52 [==============================] - 373s 7s/step - loss: 0.3590 - accuracy: 0.8601 - val_loss: 3.0913 - val_accuracy: 0.1935\n",
            "Epoch 38/200\n",
            "52/52 [==============================] - 372s 7s/step - loss: 0.3349 - accuracy: 0.8646 - val_loss: 3.5446 - val_accuracy: 0.2201\n",
            "Epoch 39/200\n",
            "52/52 [==============================] - 370s 7s/step - loss: 0.3340 - accuracy: 0.8643 - val_loss: 3.7003 - val_accuracy: 0.2261\n",
            "Epoch 40/200\n",
            "52/52 [==============================] - 370s 7s/step - loss: 0.3332 - accuracy: 0.8677 - val_loss: 3.5358 - val_accuracy: 0.1971\n",
            "Epoch 41/200\n",
            "52/52 [==============================] - 370s 7s/step - loss: 0.3454 - accuracy: 0.8634 - val_loss: 3.7666 - val_accuracy: 0.2346\n",
            "Epoch 42/200\n",
            "52/52 [==============================] - 375s 7s/step - loss: 0.3246 - accuracy: 0.8710 - val_loss: 4.5698 - val_accuracy: 0.2213\n",
            "Epoch 43/200\n",
            "52/52 [==============================] - 373s 7s/step - loss: 0.3364 - accuracy: 0.8670 - val_loss: 2.9770 - val_accuracy: 0.2515\n",
            "Epoch 44/200\n",
            "52/52 [==============================] - 373s 7s/step - loss: 0.3468 - accuracy: 0.8601 - val_loss: 3.7799 - val_accuracy: 0.2370\n",
            "Epoch 45/200\n",
            "52/52 [==============================] - 377s 7s/step - loss: 0.3111 - accuracy: 0.8788 - val_loss: 3.5341 - val_accuracy: 0.2322\n",
            "Epoch 46/200\n",
            "52/52 [==============================] - 382s 7s/step - loss: 0.3239 - accuracy: 0.8713 - val_loss: 3.6049 - val_accuracy: 0.2116\n",
            "Epoch 47/200\n",
            "52/52 [==============================] - 372s 7s/step - loss: 0.2988 - accuracy: 0.8773 - val_loss: 3.5906 - val_accuracy: 0.2479\n",
            "Epoch 48/200\n",
            "52/52 [==============================] - 371s 7s/step - loss: 0.3100 - accuracy: 0.8776 - val_loss: 3.8302 - val_accuracy: 0.2152\n",
            "Epoch 49/200\n",
            "38/52 [====================>.........] - ETA: 1:35 - loss: 0.2957 - accuracy: 0.8775"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcrAMlH1D_hR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "json.dump(str(modelH.history), open('history.csv', 'w'))\n",
        "model.save('Model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0TGhGMTD_hY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(y_test, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title='Unnormalized confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    \n",
        "    if normalize:\n",
        "        cm = np.round(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], 2)\n",
        "        \n",
        "    np.set_printoptions(precision=2)\n",
        "        \n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    thresh = cm.min() + (cm.max() - cm.min()) / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True expression')\n",
        "    plt.xlabel('Predicted expression')\n",
        "    plt.show()\n",
        "classes=np.array(('Boredm','Engagement','Confusion','Frustration'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu-Xi0EED_hd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_ = modelN.predict(test_set, verbose=1)\n",
        "y_pred = np.argmax(y_pred_, axis=1)\n",
        "t_te = np.argmax(y_val, axis=1)\n",
        "fig = plot_confusion_matrix(y_test=t_te, y_pred=y_pred,\n",
        "                      classes=classes,\n",
        "                      normalize=True,\n",
        "                      cmap=plt.cm.Greys,\n",
        "                      title='Average accuracy: ' + str(np.sum(y_pred == t_te)/len(t_te)) + ' over test data\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMOlrUsID_hi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_ = modelN.predict(training_set, verbose=1)\n",
        "y_pred = np.argmax(y_pred_, axis=1)\n",
        "t_te = np.argmax(y_val, axis=1)\n",
        "fig = plot_confusion_matrix(y_test=t_te, y_pred=y_pred,\n",
        "                      classes=classes,\n",
        "                      normalize=True,\n",
        "                      cmap=plt.cm.Greys,\n",
        "                      title='Average accuracy: ' + str(np.sum(y_pred == t_te)/len(t_te)) + ' over train data\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}